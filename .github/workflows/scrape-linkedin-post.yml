name: Scrape LinkedIn Post

on:
  workflow_dispatch:
    inputs:
      job_id:
        description: 'Job ID from database'
        required: true
        type: string
      linkedin_url:
        description: 'LinkedIn post URL to scrape'
        required: true
        type: string
      user_id:
        description: 'User ID who submitted the post'
        required: true
        type: string

jobs:
  scrape-post:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Cache Playwright browsers
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/ms-playwright
        key: ${{ runner.os }}-playwright-${{ hashFiles('package-lock.json') }}
        restore-keys: |
          ${{ runner.os }}-playwright-

    - name: Install Playwright browsers
      run: npx playwright install --with-deps chromium

    - name: Run LinkedIn scraping
      env:
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        PUBLIC_SUPABASE_URL: ${{ secrets.PUBLIC_SUPABASE_URL }}
        PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.PUBLIC_SUPABASE_ANON_KEY }}
      run: |
        node -e "
        (async () => {
          // Retry function
          const maxRetries = 3;
          const retryDelay = 5000;
          
          async function retryOperation(operation, retries = maxRetries) {
            for (let i = 0; i < retries; i++) {
              try {
                return await operation();
              } catch (error) {
                console.error('‚ùå Attempt ' + (i + 1) + ' failed:', error.message);
                if (i === retries - 1) throw error;
                console.log('‚è±Ô∏è  Waiting ' + retryDelay + 'ms before retry...');
                await new Promise(resolve => setTimeout(resolve, retryDelay));
              }
            }
          }

          try {
            console.log('üîÑ Starting LinkedIn scraping for job ${{ github.event.inputs.job_id }}');
            
            // Quick environment check
            const url = process.env.PUBLIC_SUPABASE_URL;
            const key = process.env.SUPABASE_SERVICE_KEY;
            console.log('Environment check - URL present:', !!url, 'KEY present:', !!key);
            
            // Import required modules
            const { scrapeSinglePostQueued } = await import('./src/lib/linkedin-scraper-pool.js');
            const { 
              calculatePostScore, 
              updateUserStats, 
              checkAndAwardAchievements 
            } = await import('./src/lib/gamification-node.js');
            const { supabaseAdmin } = await import('./src/lib/supabase-node.js');
            const { randomUUID } = await import('crypto');
            
            const linkedinUrl = '${{ github.event.inputs.linkedin_url }}';
            const userId = '${{ github.event.inputs.user_id }}';
            const jobId = '${{ github.event.inputs.job_id }}';
            
            // Scrape the LinkedIn post
            console.log('üì° Scraping LinkedIn post:', linkedinUrl);
            const scrapedData = await scrapeSinglePostQueued(linkedinUrl, userId);
            
            if (!scrapedData) {
              throw new Error('No data could be extracted from the post');
            }
            
            console.log('‚úÖ Successfully scraped data:', {
              reactions: scrapedData.reactions,
              comments: scrapedData.comments,
              reposts: scrapedData.reposts,
              wordCount: scrapedData.word_count
            });
            
            // Get user's current streak for scoring
            const { data: userPosts } = await supabaseAdmin
              .from('linkedin_posts')
              .select('totalScore, postedAt')
              .eq('userId', userId)
              .order('postedAt', { ascending: false });
            
            const currentStreak = userPosts && userPosts.length > 0 ? 
              Math.max(...userPosts.map((p) => p.totalScore)) : 0;
            
            // Calculate scoring
            const scoring = calculatePostScore({
              word_count: scrapedData.word_count,
              reactions: scrapedData.reactions,
              comments: scrapedData.comments,
              reposts: scrapedData.reposts,
              timestamp: scrapedData.timestamp
            }, currentStreak);
            
            console.log('üéØ Calculated scores:', scoring);
            
            // Save to database using upsert pattern with retry logic
            const linkedinId = scrapedData.id || scrapedData.linkedinId;
            let savedPost = null;
            
            try {
              await retryOperation(async () => {
                // First try to find existing post
                const { data: existingPost } = await supabaseAdmin
                  .from('linkedin_posts')
                  .select('id')
                  .eq('linkedinId', linkedinId)
                  .single();
                
                if (existingPost) {
                  // Update existing post
                  const { data: updatedPost, error: updateError } = await supabaseAdmin
                    .from('linkedin_posts')
                    .update({
                      reactions: scrapedData.reactions,
                      comments: scrapedData.comments,
                      reposts: scrapedData.reposts,
                      totalEngagement: scrapedData.total_engagement,
                      baseScore: scoring.baseScore,
                      engagementScore: scoring.engagementScore,
                      totalScore: scoring.totalScore,
                      lastScrapedAt: new Date().toISOString()
                    })
                    .eq('linkedinId', linkedinId)
                    .select()
                    .single();
                  
                  if (updateError) throw updateError;
                  savedPost = updatedPost;
                  console.log('üìù Updated existing post in database');
                } else {
                  // Create new post
                  const postId = randomUUID();
                  
                  const { data: newPost, error: createError } = await supabaseAdmin
                    .from('linkedin_posts')
                    .insert({
                      id: postId,
                      userId,
                      linkedinId: linkedinId,
                      url: linkedinUrl,
                      content: scrapedData.text || scrapedData.content,
                      authorName: scrapedData.author || scrapedData.authorName,
                      reactions: scrapedData.reactions,
                      comments: scrapedData.comments,
                      reposts: scrapedData.reposts,
                      totalEngagement: scrapedData.total_engagement,
                      baseScore: scoring.baseScore,
                      engagementScore: scoring.engagementScore,
                      totalScore: scoring.totalScore,
                      wordCount: scrapedData.word_count,
                      charCount: scrapedData.char_count,
                      postedAt: new Date(scrapedData.timestamp || scrapedData.postedAt).toISOString(),
                      lastScrapedAt: new Date().toISOString()
                    })
                    .select()
                    .single();
                  
                  if (createError) throw createError;
                  savedPost = newPost;
                  console.log('‚ú® Created new post in database');
                }
              });
            } catch (dbError) {
              console.error('‚ö†Ô∏è  Database save failed after retries:', dbError.message);
              console.log('üìä Scraped data will be logged for manual recovery:');
              console.log(JSON.stringify({
                linkedinUrl,
                userId,
                jobId,
                scrapedData,
                scoring
              }, null, 2));
              
              // If we can't save the post, we can't create analytics - throw the error
              throw new Error('Failed to save post to database: ' + dbError.message);
            }
            
            // Create analytics record
            try {
              const analyticsId = randomUUID();
              
              const { error: analyticsError } = await supabaseAdmin
                .from('post_analytics')
                .insert({
                  id: analyticsId,
                  postId: savedPost.id,
                  reactions: scrapedData.reactions,
                  comments: scrapedData.comments,
                  reposts: scrapedData.reposts,
                  totalEngagement: scrapedData.total_engagement,
                  reactionGrowth: 0,
                  commentGrowth: 0,
                  repostGrowth: 0
                });
              
              if (analyticsError) {
                console.log('Analytics creation failed:', analyticsError.message);
              } else {
                console.log('üìä Created analytics record');
              }
            } catch (analyticsError) {
              console.log('Analytics creation failed:', analyticsError.message);
            }
            
            // Update user stats (with fallback)
            try {
              console.log('üë§ Updating user stats...');
              await retryOperation(async () => {
                await updateUserStats(userId);
                console.log('‚úÖ User stats updated');
              });
            } catch (error) {
              console.error('‚ö†Ô∏è  User stats update failed:', error.message);
            }
            
            // Check for new achievements (with fallback)
            let newAchievements = [];
            try {
              console.log('üèÜ Checking for new achievements...');
              newAchievements = await retryOperation(async () => {
                const achievements = await checkAndAwardAchievements(userId);
                console.log('‚úÖ Achievements checked');
                return achievements;
              });
            } catch (error) {
              console.error('‚ö†Ô∏è  Achievement check failed:', error.message);
            }
            
            // Update job status to completed (with fallback)
            try {
              await retryOperation(async () => {
                const { error: jobUpdateError } = await supabaseAdmin
                  .from('jobs')
                  .update({ 
                    status: 'COMPLETED',
                    completedAt: new Date().toISOString(),
                    result: JSON.stringify({
                      post: savedPost,
                      scoring: scoring,
                      newAchievements: newAchievements
                    })
                  })
                  .eq('id', jobId);
                
                if (jobUpdateError) throw jobUpdateError;
                console.log('‚úÖ Job status updated to COMPLETED');
              });
            } catch (error) {
              console.error('‚ö†Ô∏è  Job status update failed:', error.message);
              console.log('üìä Final results logged for manual processing');
            }
            
            console.log('üéâ Scraping workflow completed successfully');
            process.exit(0);
            
          } catch (error) {
            console.error('‚ùå Scraping failed:', error.message);
            
            // Update job status to failed
            const { supabaseAdmin } = await import('./src/lib/supabase-node.js');
            await supabaseAdmin
              .from('jobs')
              .update({ 
                status: 'FAILED',
                failedAt: new Date().toISOString(),
                error: error.message
              })
              .eq('id', '${{ github.event.inputs.job_id }}');
            
            process.exit(1);
          }
        })();
        "