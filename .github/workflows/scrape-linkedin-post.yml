name: Scrape LinkedIn Post

on:
  workflow_dispatch:
    inputs:
      job_id:
        description: 'Job ID from database'
        required: true
        type: string
      linkedin_url:
        description: 'LinkedIn post URL to scrape'
        required: true
        type: string
      user_id:
        description: 'User ID who submitted the post'
        required: true
        type: string

jobs:
  scrape-post:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Install Playwright browsers
      run: npx playwright install --with-deps chromium

    - name: Update job status to processing
      env:
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        PUBLIC_SUPABASE_URL: ${{ secrets.PUBLIC_SUPABASE_URL }}
      run: |
        node -e "
        import('./src/lib/supabase-node.js').then(async ({ supabaseAdmin }) => {
          const { error } = await supabaseAdmin
            .from('jobs')
            .update({ 
              status: 'PROCESSING',
              startedAt: new Date().toISOString()
            })
            .eq('id', '${{ github.event.inputs.job_id }}');
          if (error) console.error('Failed to update job status:', error);
          else console.log('Job status updated to PROCESSING');
        });
        "

    - name: Run LinkedIn scraping
      env:
        SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        PUBLIC_SUPABASE_URL: ${{ secrets.PUBLIC_SUPABASE_URL }}
        PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.PUBLIC_SUPABASE_ANON_KEY }}
      run: |
        node -e "
        (async () => {
          try {
            console.log('üîÑ Starting LinkedIn scraping for job ${{ github.event.inputs.job_id }}');
            
            // Import required modules
            const { scrapeSinglePostQueued } = await import('./src/lib/linkedin-scraper-pool.js');
            const { 
              calculatePostScore, 
              updateUserStats, 
              checkAndAwardAchievements 
            } = await import('./src/lib/gamification-node.js');
            const { supabaseAdmin } = await import('./src/lib/supabase-node.js');
            const { randomUUID } = await import('crypto');
            
            const linkedinUrl = '${{ github.event.inputs.linkedin_url }}';
            const userId = '${{ github.event.inputs.user_id }}';
            const jobId = '${{ github.event.inputs.job_id }}';
            
            // Scrape the LinkedIn post
            console.log('üì° Scraping LinkedIn post:', linkedinUrl);
            const scrapedData = await scrapeSinglePostQueued(linkedinUrl, userId);
            
            if (!scrapedData) {
              throw new Error('No data could be extracted from the post');
            }
            
            console.log('‚úÖ Successfully scraped data:', {
              reactions: scrapedData.reactions,
              comments: scrapedData.comments,
              reposts: scrapedData.reposts,
              wordCount: scrapedData.word_count
            });
            
            // Get user's current streak for scoring
            const { data: userPosts } = await supabaseAdmin
              .from('linkedin_posts')
              .select('totalScore, postedAt')
              .eq('userId', userId)
              .order('postedAt', { ascending: false });
            
            const currentStreak = userPosts && userPosts.length > 0 ? 
              Math.max(...userPosts.map((p) => p.totalScore)) : 0;
            
            // Calculate scoring
            const scoring = calculatePostScore({
              word_count: scrapedData.word_count,
              reactions: scrapedData.reactions,
              comments: scrapedData.comments,
              reposts: scrapedData.reposts,
              timestamp: scrapedData.timestamp
            }, currentStreak);
            
            console.log('üéØ Calculated scores:', scoring);
            
            // Save to database using upsert pattern
            const linkedinId = scrapedData.id || scrapedData.linkedinId;
            
            // First try to find existing post
            const { data: existingPost } = await supabaseAdmin
              .from('linkedin_posts')
              .select('id')
              .eq('linkedinId', linkedinId)
              .single();
            
            let savedPost;
            if (existingPost) {
              // Update existing post
              const { data: updatedPost, error: updateError } = await supabaseAdmin
                .from('linkedin_posts')
                .update({
                  reactions: scrapedData.reactions,
                  comments: scrapedData.comments,
                  reposts: scrapedData.reposts,
                  totalEngagement: scrapedData.total_engagement,
                  baseScore: scoring.baseScore,
                  engagementScore: scoring.engagementScore,
                  totalScore: scoring.totalScore,
                  lastScrapedAt: new Date().toISOString()
                })
                .eq('linkedinId', linkedinId)
                .select()
                .single();
              
              if (updateError) {
                throw new Error(\`Failed to update post: \${updateError.message}\`);
              }
              savedPost = updatedPost;
              console.log('üìù Updated existing post in database');
            } else {
              // Create new post
              const postId = randomUUID();
              
              const { data: newPost, error: createError } = await supabaseAdmin
                .from('linkedin_posts')
                .insert({
                  id: postId,
                  userId,
                  linkedinId: linkedinId,
                  url: linkedinUrl,
                  content: scrapedData.text || scrapedData.content,
                  authorName: scrapedData.author || scrapedData.authorName,
                  reactions: scrapedData.reactions,
                  comments: scrapedData.comments,
                  reposts: scrapedData.reposts,
                  totalEngagement: scrapedData.total_engagement,
                  baseScore: scoring.baseScore,
                  engagementScore: scoring.engagementScore,
                  totalScore: scoring.totalScore,
                  wordCount: scrapedData.word_count,
                  charCount: scrapedData.char_count,
                  postedAt: new Date(scrapedData.timestamp || scrapedData.postedAt).toISOString(),
                  lastScrapedAt: new Date().toISOString()
                })
                .select()
                .single();
              
              if (createError) {
                throw new Error(\`Failed to create post: \${createError.message}\`);
              }
              savedPost = newPost;
              console.log('‚ú® Created new post in database');
            }
            
            // Create analytics record
            try {
              const analyticsId = randomUUID();
              
              const { error: analyticsError } = await supabaseAdmin
                .from('post_analytics')
                .insert({
                  id: analyticsId,
                  postId: savedPost.id,
                  reactions: scrapedData.reactions,
                  comments: scrapedData.comments,
                  reposts: scrapedData.reposts,
                  totalEngagement: scrapedData.total_engagement,
                  reactionGrowth: 0,
                  commentGrowth: 0,
                  repostGrowth: 0
                });
              
              if (analyticsError) {
                console.log('Analytics creation failed:', analyticsError.message);
              } else {
                console.log('üìä Created analytics record');
              }
            } catch (analyticsError) {
              console.log('Analytics creation failed:', analyticsError.message);
            }
            
            // Update user stats
            console.log('üë§ Updating user stats...');
            await updateUserStats(userId);
            
            // Check for new achievements
            console.log('üèÜ Checking for new achievements...');
            const newAchievements = await checkAndAwardAchievements(userId);
            
            // Update job status to completed
            const { error: jobUpdateError } = await supabaseAdmin
              .from('jobs')
              .update({ 
                status: 'COMPLETED',
                completedAt: new Date().toISOString(),
                result: JSON.stringify({
                  post: savedPost,
                  scoring: scoring,
                  newAchievements: newAchievements
                })
              })
              .eq('id', jobId);
            
            if (jobUpdateError) {
              console.error('Failed to update job status:', jobUpdateError);
            } else {
              console.log('‚úÖ Job completed successfully');
            }
            
            console.log('üéâ Scraping workflow completed successfully');
            
          } catch (error) {
            console.error('‚ùå Scraping failed:', error.message);
            
            // Update job status to failed
            const { supabaseAdmin } = await import('./src/lib/supabase-node.js');
            await supabaseAdmin
              .from('jobs')
              .update({ 
                status: 'FAILED',
                failedAt: new Date().toISOString(),
                error: error.message
              })
              .eq('id', '${{ github.event.inputs.job_id }}');
            
            process.exit(1);
          }
        })();
        "